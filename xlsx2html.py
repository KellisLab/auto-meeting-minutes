"""
xlsx2html.py - Convert Excel transcript files to HTML with links and summaries
Usage: python xlsx2html.py input.xlsx video_id [output.html] [--format={simple|numbered}]

This script takes an Excel file generated by txt2xlsx.py and:
1. Creates direct links to video timestamps for all speakers
2. Generates AI-powered summaries for transcript sections
3. Places the summaries near their corresponding speaker links
4. Generates separate HTML and Markdown files with:
  - Speaker summaries with direct timestamp links
  - Meeting summaries organized by batch with links to both batch start times and
    individual topic timestamps within each batch
  - Topic-level navigation within meeting summaries

Examples:
python xlsx2html.py meeting.xlsx 757a2c7c-eb52-47d1-9b4a-b2a1014b530b
python xlsx2html.py meeting.xlsx 757a2c7c-eb52-47d1-9b4a-b2a1014b530b meeting_links.html --format=numbered
"""

import sys
import os
import pandas as pd
import argparse
import re
import time
import json
import openai
from dotenv import load_dotenv
import numpy as np
import importlib.util

# -------------------------------------------------------------
# Constants and Configuration
# -------------------------------------------------------------
# load API KEY from .env
load_dotenv()
# Access the API key
OPENAI_API_KEY = os.getenv("API_KEY")
MODEL = os.getenv("GPT_MODEL", "gpt-4o")
# Default batch size for meeting summaries (in minutes)
DEFAULT_BATCH_SIZE_MINUTES = 40


# -------------------------------------------------------------
# Helper Functions
# -------------------------------------------------------------
def seconds_to_time_str(seconds):
    """
    Convert seconds to H:MM:SS format (e.g., 0:18:52)
    """
    if pd.isna(seconds):
        return "00:00:00"
    
    hours, remainder = divmod(int(seconds), 3600)
    minutes, seconds = divmod(remainder, 60)
    return f"{hours}:{minutes:02d}:{seconds:02d}"

def time_str_to_seconds(time_str):
    """
    Convert H:MM:SS time string to seconds
    
    Args:
        time_str (str): Time string in format H:MM:SS
        
    Returns:
        int: Total seconds
    """
    parts = time_str.split(':')
    if len(parts) == 3:
        hours, minutes, seconds = map(int, parts)
        return hours * 3600 + minutes * 60 + seconds
    else:
        # Handle MM:SS format if needed
        return 0  # Return 0 for invalid formats

# Add this utility function to xlsx2html.py

def format_corrected_timestamp(seconds):
    """
    Convert seconds to a corrected timestamp string in H:MM:SS format
    
    Args:
        seconds (int): Total seconds
        
    Returns:
        str: Formatted timestamp string
    """
    hours, remainder = divmod(int(seconds), 3600)
    minutes, seconds = divmod(remainder, 60)
    return f"{hours}:{minutes:02d}:{seconds:02d}"

def verify_timestamp_format(timestamp_str, seconds):
    """
    Verify that a timestamp string matches the seconds value
    If not, return a corrected timestamp string
    
    Args:
        timestamp_str (str): Timestamp string in H:MM:SS format
        seconds (int): The seconds value from the URL
        
    Returns:
        str: Corrected timestamp string if needed, or original if already correct
    """
    # Convert timestamp string to seconds
    try:
        parts = timestamp_str.split(':')
        if len(parts) == 3:
            hours, minutes, secs = map(int, parts)
            ts_seconds = hours * 3600 + minutes * 60 + secs
            
            # If they don't match, return a corrected timestamp
            if ts_seconds != seconds:
                return format_corrected_timestamp(seconds)
    except:
        # If parsing fails, return a corrected timestamp
        return format_corrected_timestamp(seconds)
    
    # If already correct or if can't verify, return original
    return timestamp_str

def get_column_letter(col_idx):
    """Convert column index to letter (1=A, 2=B, etc.)."""
    letter = ''
    while col_idx > 0:
        col_idx, remainder = divmod(col_idx - 1, 26)
        letter = chr(65 + remainder) + letter
    return letter

# -------------------------------------------------------------
# Data Extraction Functions
# -------------------------------------------------------------
def extract_transcript_data(df):
    """
    Extract transcript data from the DataFrame
    
    Args:
        df (pandas.DataFrame): The Excel DataFrame
        
    Returns:
        list: List of dictionaries with transcript data
    """
    transcript_data = []
    
    if 'Name' in df.columns and 'Seconds' in df.columns and 'Text' in df.columns:
        for i, row in df.iterrows():
            if pd.notna(row['Name']) and pd.notna(row['Seconds']) and pd.notna(row['Text']):
                entry = {
                    'name': row['Name'],
                    'seconds': int(row['Seconds']),
                    'time_str': seconds_to_time_str(row['Seconds']),
                    'text': row['Text'],
                    'row_index': i  # Add row index for reference
                }
                
                # Add time_end if available (used by refineStartTimes.py)
                if 'End_Seconds' in df.columns and pd.notna(row['End_Seconds']):
                    entry['end_seconds'] = int(row['End_Seconds'])
                    entry['end_time_str'] = seconds_to_time_str(row['End_Seconds'])
                
                # Add topic information if available
                if 'Topic' in df.columns and pd.notna(row['Topic']):
                    entry['topic'] = row['Topic']
                
                # Add matched seconds if available
                if 'Matched_Seconds' in df.columns and pd.notna(row['Matched_Seconds']):
                    entry['matched_seconds'] = int(row['Matched_Seconds'])
                    entry['matched_time_str'] = seconds_to_time_str(row['Matched_Seconds'])
                
                transcript_data.append(entry)
    else:
        raise ValueError("Excel file doesn't contain the expected columns (Name, Seconds, Text)")
    
    # Sort by timestamp
    transcript_data.sort(key=lambda x: x['seconds'])
    return transcript_data

def extract_unique_speakers(df):
    """
    Extract unique speakers from the DataFrame
    First try using 'First' column for first occurrences only,
    then fallback to using all 'Name' entries
    
    Args:
        df (pandas.DataFrame): The Excel DataFrame
        
    Returns:
        list: List of dictionaries with unique speaker data
    """
    speaker_data = []
    
    # First, check if we're using the First columns for unique speakers
    if 'First' in df.columns and 'First_Seconds' in df.columns and df['First'].notna().any():
        unique_speakers = df[df['First'].notna()]
        for i, row in unique_speakers.iterrows():
            if pd.notna(row['First']) and pd.notna(row['First_Seconds']):
                speaker_data.append({
                    'name': row['First'],
                    'seconds': int(row['First_Seconds']),
                    'time_str': seconds_to_time_str(row['First_Seconds']),
                    'row_index': i  # Add row index for reference
                })
    # Fallback to using all rows if no "First" column or no data there
    elif 'Name' in df.columns and 'Seconds' in df.columns:
        seen_speakers = set()
        for i, row in df.iterrows():
            if pd.notna(row['Name']) and pd.notna(row['Seconds']):
                if row['Name'] not in seen_speakers:
                    seen_speakers.add(row['Name'])
                    speaker_data.append({
                        'name': row['Name'],
                        'seconds': int(row['Seconds']),
                        'time_str': seconds_to_time_str(row['Seconds']),
                        'row_index': i  # Add row index for reference
                    })
    else:
        raise ValueError("Excel file doesn't contain the expected columns (Name/Seconds or First/First_Seconds)")
    
    # Sort by timestamp
    speaker_data.sort(key=lambda x: x['seconds'])
    return speaker_data

# -------------------------------------------------------------
# Batch Creation and Text Extraction
# -------------------------------------------------------------
def create_time_batches(transcript_data, batch_size_minutes=DEFAULT_BATCH_SIZE_MINUTES):
    """
    Create time-based batches directly from transcript data
    
    Args:
        transcript_data (list): List of transcript entries
        batch_size_minutes (int): Batch size in minutes
        
    Returns:
        list: List of batches, each containing transcript entries
    """
    if not transcript_data:
        return []
    
    # Get start and end time of the meeting
    start_time = transcript_data[0]['seconds']
    
    # Determine end time - either from explicit end_seconds or last entry plus buffer
    if 'end_seconds' in transcript_data[-1]:
        end_time = transcript_data[-1]['end_seconds']
    else:
        end_time = transcript_data[-1]['seconds'] + 60  # Add a small buffer
    
    # Convert batch size to seconds
    batch_size_seconds = batch_size_minutes * 60
    
    # Calculate total duration
    total_duration = end_time - start_time
    
    # For short meetings (less than batch size), create a single batch
    if total_duration <= batch_size_seconds:
        return [transcript_data]
    
    # For longer meetings, create time-based batches
    batches = []
    batch_start = start_time
    
    while batch_start < end_time:
        batch_end = min(batch_start + batch_size_seconds, end_time)
        
        # Get entries for this time range
        batch_entries = [
            entry for entry in transcript_data
            if batch_start <= entry['seconds'] < batch_end
        ]
        
        # Only add non-empty batches
        if batch_entries:
            batches.append(batch_entries)
        
        # Move to next batch
        batch_start = batch_end
    
    return batches

def extract_text_for_batch(batch_entries):
    """
    Extract transcript text for a batch of entries
    
    Args:
        batch_entries (list): List of transcript entries for the batch
        
    Returns:
        str: Concatenated text for the batch
    """
    batch_text = ""
    
    # Sort by timestamp
    sorted_entries = sorted(batch_entries, key=lambda x: x['seconds'])
    
    # Concatenate text from all entries
    for entry in sorted_entries:
        batch_text += f"{entry['name']}: {entry['text']}\n\n"
    
    return batch_text

# -------------------------------------------------------------
# Topic Extraction and Matching
# -------------------------------------------------------------
def find_best_timestamp_match(topic_content, speaker_name, transcript_data):
    """
    Find the best timestamp match for a topic in the transcript
    
    Args:
        topic_content (str): Content text of the topic
        speaker_name (str): Name of the speaker
        transcript_data (list): List of transcript entries
        
    Returns:
        dict: The best matching transcript entry
    """
    # First, filter by speaker
    speaker_entries = [entry for entry in transcript_data if entry['name'] == speaker_name]
    
    if not speaker_entries:
        return None
    
    # Try to import the refineStartTimes module
    try:
        module_name = "refineStartTimes"
        if module_name in sys.modules:
            refine_module = sys.modules[module_name]
        else:
            # Look for the module in the current directory
            module_path = os.path.join(os.path.dirname(__file__), "refineStartTimes.py")
            if os.path.exists(module_path):
                spec = importlib.util.spec_from_file_location(module_name, module_path)
                refine_module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(refine_module)
            else:
                raise ImportError("refineStartTimes.py not found")
        
        # Use the advanced matching algorithm from refineStartTimes
        if hasattr(refine_module, 'find_best_timestamp_match'):
            return refine_module.find_best_timestamp_match(topic_content, speaker_name, speaker_entries)
    except Exception as e:
        # Fall back to basic matching if import fails
        print(f"Warning: Could not use refineStartTimes for matching: {e}")
    
    # Basic matching (fallback)
    # First check if any entry has matching topic information
    topic_entries = [entry for entry in speaker_entries if 
                    'topic' in entry and entry['topic'] is not None]
    
    if topic_entries:
        # Return the first entry with topic information
        return topic_entries[0]
    
    # If no topic entries found, use basic text similarity matching
    # Use a very simple approach - look for keyword overlap
    topic_words = set(topic_content.lower().split())
    best_match = None
    highest_score = 0
    
    for entry in speaker_entries:
        entry_words = set(entry['text'].lower().split())
        # Calculate word overlap
        overlap = len(topic_words & entry_words)
        # Normalize by the length of the shorter text
        score = overlap / min(len(topic_words), len(entry_words)) if min(len(topic_words), len(entry_words)) > 0 else 0
        
        if score > highest_score:
            highest_score = score
            best_match = entry
    
    # If we found a decent match, return it
    if best_match and highest_score > 0.1:
        return best_match
    
    # Default: return the first entry for this speaker
    return speaker_entries[0]

def update_speaker_timestamps_for_topics(topics, transcript_data):
    """
    Update topic timestamps to better match the actual content
    
    Args:
        topics (list): List of topic dictionaries extracted from summaries
        transcript_data (list): List of transcript entries for matching
        
    Returns:
        list: Updated list of topic dictionaries
    """
    for topic in topics:
        speaker = topic['speaker']
        content = topic['content']
        
        # Find the best matching entry for this topic/speaker
        best_match = find_best_timestamp_match(content, speaker, transcript_data)
        
        if best_match:
            # Update the timestamp to the matched entry
            matched_seconds = best_match.get('matched_seconds', best_match.get('seconds'))
            matched_time_str = best_match.get('matched_time_str', 
                                             seconds_to_time_str(matched_seconds))
            
            # Only update if this is different from the original
            if topic['timestamp_seconds'] != matched_seconds:
                print(f"Updated timestamp for topic '{topic['topic']}' by {speaker} from " 
                      f"{topic['timestamp']} to {matched_time_str}")
                
                topic['timestamp_seconds'] = matched_seconds
                topic['timestamp'] = matched_time_str
                
                # Update the video link as well if video_id is present
                if 'video_link' in topic and topic['video_link']:
                    video_id = re.search(r'id=([^&]+)', topic['video_link']).group(1)
                    topic['video_link'] = f'https://mit.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id={video_id}&start={matched_seconds}'
    
    return topics

def extract_topics_from_summary(summary, video_id=None, transcript_data=None):
    """
    Extract individual topics from a batch summary.
    Looks for bold titles in the format: **Topic Title - Speaker Name** (H:MM:SS)
    Returns a list of dictionaries with topic, speaker, timestamp, and content info.
    
    Args:
        summary (str): The batch summary text
        video_id (str, optional): Panopto video ID for creating direct links
        transcript_data (list, optional): Transcript data for better timestamp matching
        
    Returns:
        list: List of topic dictionaries
    """
    import re
    
    # Updated pattern to match: **Topic - Speaker** (H:MM:SS): followed by text
    # This captures the timestamp if present
    pattern = r'\*\*(.+?)\s*-\s*(.+?)\*\*\s*(?:\((\d+:\d{2}:\d{2})\))?\s*:'
    
    # Find all matches in the summary
    topic_matches = list(re.finditer(pattern, summary))
    
    topics = []
    
    for idx, match in enumerate(topic_matches):
        topic = match.group(1).strip()
        # Keep only the first speaker if multiple are present
        speaker_raw = match.group(2).strip()
        speaker = re.split(r'\s*&\s*|,\s*| and ', speaker_raw, maxsplit=1)[0]
        
        # Get timestamp if present
        timestamp = match.group(3)
        timestamp_seconds = None
        video_link = None
        
        # Convert timestamp to seconds if present and video_id is provided
        if timestamp and video_id:
            timestamp_seconds = time_str_to_seconds(timestamp)
            
            # If transcript data is provided, try to find a better timestamp match for this topic/speaker
            if transcript_data:
                start_pos = match.end()
                # Determine end of content: either next match or end of summary
                next_start = topic_matches[idx + 1].start() if idx + 1 < len(topic_matches) else len(summary)
                topic_content = summary[start_pos:next_start].strip()
                
                # Find the best matching entry for this topic/speaker
                best_match = find_best_timestamp_match(topic_content, speaker, transcript_data)
                if best_match:
                    # Use the matched timestamp instead
                    timestamp_seconds = best_match.get('matched_seconds', best_match.get('seconds', timestamp_seconds))
            
            # Create the video link with the appropriate timestamp
            video_link = f'https://mit.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id={video_id}&start={timestamp_seconds}'
        
        start_pos = match.start()
        end_pos = match.end()
        
        # Determine end of content: either next match or end of summary
        next_start = topic_matches[idx + 1].start() if idx + 1 < len(topic_matches) else len(summary)
        
        content = summary[end_pos:next_start].strip()
        
        topics.append({
            'topic': topic,
            'speaker': speaker,
            'timestamp': timestamp,
            'timestamp_seconds': timestamp_seconds,
            'video_link': video_link,
            'position': start_pos,
            'content': content,
            'full_match': match.group(0)
        })
    
    return topics

# -------------------------------------------------------------
# HTML and Markdown Generation Functions
# -------------------------------------------------------------
def generate_meeting_summaries_html(batches, batch_summaries, video_id, html_file, transcript_data=None):
    """
    Generate HTML file with meeting batch summaries that include clickable timestamp links
    for both batches and individual topics within each batch.
    Uses intelligent topic-to-timestamp matching when transcript_data is provided.
    
    Args:
        batches (list): List of batch entries
        batch_summaries (list): List of batch summaries
        video_id (str): Panopto video ID
        html_file (str): Output HTML file path
        transcript_data (list, optional): Full transcript data for better timestamp matching
        
    Returns:
        str: Path to the generated HTML file
    """
    html_lines = []
    
    html_lines.append('<h1>Meeting Summaries</h1>')
    
    for i, (batch, summary) in enumerate(zip(batches, batch_summaries), 1):
        # Find the start and end times for this batch
        start_seconds = min(entry['seconds'] for entry in batch)
        # End time is either explicit end_seconds or last entry
        if any('end_seconds' in entry for entry in batch):
            # Use the max end_seconds if available
            end_seconds = max(entry.get('end_seconds', entry['seconds']) for entry in batch)
        else:
            # Otherwise use the last entry in the batch
            end_seconds = max(entry['seconds'] for entry in batch)
        
        start_time = seconds_to_time_str(start_seconds)
        end_time = seconds_to_time_str(end_seconds)
        
        # Create a link to the video at this timestamp
        video_link = f'https://mit.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id={video_id}&start={start_seconds}'
        
        # Add batch heading with clickable link
        # html_lines.append(f'<h2>Batch {i}: <a href="{video_link}">{start_time} - {end_time}</a></h2>')
        
        # Extract topics from the summary with their timestamps
        topics = extract_topics_from_summary(summary, video_id, transcript_data)
        
        # If we have transcript data, update the topic timestamps to better match content
        if transcript_data:
            topics = update_speaker_timestamps_for_topics(topics, transcript_data)
        
        if topics:
            # Create a div for all topics in this batch
            html_lines.append('<div class="batch-topics">')
            
            # Process each topic with its direct timestamp link if available
            for topic_info in topics:
                topic = topic_info['topic']
                speaker = topic_info['speaker']
                content = topic_info['content']
                
                # Check if the topic has a direct timestamp link from the summary
                if topic_info['video_link']:
                    # Use the direct link from the timestamp in the summary
                    topic_link = topic_info['video_link']
                    timestamp = topic_info['timestamp']
                    
                    # Add topic as a subheading with direct link from the summary
                    html_lines.append(f'<h3><a href="{topic_link}" class="topic-link">{topic} - {speaker}</a> ({timestamp})</h3>')
                else:
                    # Fallback: Find the entry for this speaker in the batch
                    speaker_entry = None
                    for entry in batch:
                        if entry['name'] == speaker:
                            speaker_entry = entry
                            break
                    
                    # If we found the entry, create a link to it
                    if speaker_entry:
                        speaker_seconds = speaker_entry['seconds']
                        speaker_time = speaker_entry['time_str']
                        topic_link = f'https://mit.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id={video_id}&start={speaker_seconds}'
                        
                        # Add topic as a subheading with link from entry
                        html_lines.append(f'<h3><a href="{topic_link}" class="topic-link">{topic} - {speaker}</a> ({speaker_time})</h3>')
                    else:
                        # If no entry found, just display the topic without a link
                        html_lines.append(f'<h3>{topic} - {speaker}</h3>')
                
                # Add the content for this topic
                html_lines.append(f'<div class="topic-content">{content}</div>')
            
            html_lines.append('</div>') # Close batch-topics div
        else:
            # If no topics were extracted, just show the full summary
            html_lines.append(f'<div class="batch-summary">{summary}</div>')
        
        # Add separator
        html_lines.append('<hr>')
    
    # Combine all lines into HTML
    html_content = '<html>\n<head>\n<title>Meeting Summaries</title>\n'
    html_content += '<style>\n'
    html_content += 'body { font-family: Arial, sans-serif; margin: 20px; }\n'
    html_content += '.batch-summary, .topic-content { margin-bottom: 20px; }\n'
    html_content += 'h2 { color: #333; }\n'
    html_content += 'h3 { color: #555; margin-top: 15px; }\n'
    html_content += 'a { color: #0066cc; }\n'
    html_content += '.topic-link { text-decoration: none; color: #0066cc; }\n'
    html_content += '.topic-link:hover { text-decoration: underline; }\n'
    html_content += '</style>\n</head>\n<body>\n'
    html_content += '\n'.join(html_lines)
    html_content += '\n</body>\n</html>'
    
    # Write the file
    with open(html_file, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    return html_file

def generate_meeting_summaries_markdown(batches, batch_summaries, video_id, md_file, transcript_data=None):
    """
    Generate Markdown file with meeting batch summaries that include clickable timestamp links
    for both batches and individual topics within each batch.
    Topics are sorted chronologically by timestamp, and timestamps are verified to match URL seconds.
    
    Args:
        batches (list): List of batch entries
        batch_summaries (list): List of batch summaries
        video_id (str): Panopto video ID
        md_file (str): Output Markdown file path
        transcript_data (list, optional): Full transcript data for better timestamp matching
        
    Returns:
        str: Path to the generated Markdown file
    """
    md_lines = []
    
    md_lines.append('# Meeting Summaries\n')
    
    # Extract all topics from all batches
    all_topics = []
    
    for i, (batch, summary) in enumerate(zip(batches, batch_summaries), 1):
        # Extract topics from the summary with their timestamps
        topics = extract_topics_from_summary(summary, video_id, transcript_data)
        
        # If we have transcript data, update the topic timestamps to better match content
        if transcript_data:
            topics = update_speaker_timestamps_for_topics(topics, transcript_data)
        
        # Add batch index for reference
        for topic in topics:
            topic['batch_index'] = i
            topic['batch'] = batch
        
        all_topics.extend(topics)
    
    # Sort all topics by timestamp_seconds
    all_topics.sort(key=lambda x: x['timestamp_seconds'] if x['timestamp_seconds'] is not None else float('inf'))
    
    # Process each topic
    for topic_info in all_topics:
        topic = topic_info['topic']
        speaker = topic_info['speaker']
        content = topic_info['content']
        batch = topic_info['batch']
        
        # Check if the topic has a direct timestamp link
        if topic_info['video_link'] and topic_info['timestamp_seconds'] is not None:
            # Use the direct link from the timestamp in the summary
            topic_link = topic_info['video_link']
            seconds = topic_info['timestamp_seconds']
            
            # Verify the timestamp matches the seconds value
            # If not, get a corrected timestamp
            corrected_timestamp = verify_timestamp_format(topic_info['timestamp'], seconds)
            
            # Add topic as a subheading with direct link and corrected timestamp
            md_lines.append(f'**{topic} - {speaker}** [({corrected_timestamp})]({topic_link})')
        else:
            # Fallback: Find the entry for this speaker in the batch
            speaker_entry = None
            for entry in batch:
                if entry['name'] == speaker:
                    speaker_entry = entry
                    break
            
            # If we found the entry, create a link to it
            if speaker_entry:
                speaker_seconds = speaker_entry['seconds']
                speaker_time = verify_timestamp_format(speaker_entry.get('time_str', ''), speaker_seconds)
                topic_link = f'https://mit.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id={video_id}&start={speaker_seconds}'
                
                # Add topic as a subheading with link from entry
                md_lines.append(f'### {topic} - {speaker} [({speaker_time})]({topic_link})')
            else:
                # If no entry found, just display the topic without a link
                md_lines.append(f'### {topic} - {speaker}\n')
        
        # Add the content for this topic
        md_lines.append(f'{content}\n')
    
    # Write the file
    with open(md_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(md_lines))
    
    print(f"Generated meeting summaries markdown with verified timestamps: {md_file}")
    return md_file

def generate_simple_format(speaker_links, transcript_data, video_id):
    """
    Generate HTML in simple format with <br> tags and summaries
    
    Args:
        speaker_links (list): List of speaker link dictionaries
        transcript_data (list): List of transcript entry dictionaries
        video_id (str): Panopto video ID
        
    Returns:
        list: List of HTML lines
    """
    html_lines = []
    
    for i, speaker in enumerate(speaker_links):
        name = speaker['name']
        seconds = speaker['seconds']
        time_str = speaker['time_str']
        
        # Create the HTML link
        link = f'<br>{name} (<a href="https://mit.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id={video_id}&start={seconds}">{time_str}</a>)'
        html_lines.append(link)
        
        # Find summary for this speaker
        speaker_entries = [entry for entry in transcript_data if entry['name'] == name]
        if speaker_entries and 'summary' in speaker_entries[0]:
            html_lines.append(f'<div>{speaker_entries[0]["summary"]}</div>')
    
    return html_lines

def generate_numbered_format(speaker_links, transcript_data, video_id):
    """
    Generate HTML in numbered format with line breaks and summaries
    
    Args:
        speaker_links (list): List of speaker link dictionaries
        transcript_data (list): List of transcript entry dictionaries
        video_id (str): Panopto video ID
        
    Returns:
        list: List of HTML lines
    """
    html_lines = []
    
    # Add container div
    html_lines.append('<h2>Direct Links:</h2>')
    
    # Generate the numbered list
    for i, speaker in enumerate(speaker_links, 1):
        name = speaker['name']
        seconds = speaker['seconds']
        time_str = speaker['time_str']
        
        # Create the HTML link
        link = f'{i}. {name} (<a href="https://mit.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id={video_id}&start={seconds}">{time_str}</a>)'
        html_lines.append(link)
        
        # Find summary for this speaker
        speaker_entries = [entry for entry in transcript_data if entry['name'] == name]
        if speaker_entries and 'summary' in speaker_entries[0]:
            html_lines.append(f'<div>{speaker_entries[0]["summary"]}</div>')
        
        html_lines.append('<br>')
    
    # Close the div
    html_lines.append('</div>')
    
    return html_lines

def generate_speaker_summary(speaker_links, transcript_data, video_id):
    """
    Generate Markdown with speaker summaries and timestamp links
    
    Args:
        speaker_links (list): List of speaker link dictionaries
        transcript_data (list): List of transcript entry dictionaries
        video_id (str): Panopto video ID
        
    Returns:
        list: List of Markdown lines
    """
    md_lines = []
    
    # Add container div
    md_lines.append('# Speaker Summary')
    
    # Generate the numbered list
    for i, speaker in enumerate(speaker_links, 1):
        name = speaker['name']
        seconds = speaker['seconds']
        time_str = speaker['time_str']
        
        # Create the Markdown link
        link = f'{i}. **{name}** [({time_str})](https://mit.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id={video_id}&start={seconds}) - '
        md_lines.append(link)
        
        # Find summary for this speaker
        speaker_entries = [entry for entry in transcript_data if entry['name'] == name]
        if speaker_entries and 'summary' in speaker_entries[0]:
            md_lines.append(f'{speaker_entries[0]["summary"]}\n')
        else:
            # Find a significant dialog from this speaker
            significant_texts = [entry['text'] for entry in transcript_data if entry['name'] == name]
            if significant_texts:
                # Get the longest text as a representative sample
                longest_text = max(significant_texts, key=len)
                summary = f"Speaker discussed: {longest_text[:100]}..."
                md_lines.append(f'{summary}\n')
    
    return md_lines

# -------------------------------------------------------------
# OpenAI Summarization Functions
# -------------------------------------------------------------
def get_api_key():
    """
    Get OpenAI API key from constant, environment variable, or config file
    
    Returns:
        str: OpenAI API key
    """
    # Check the constant first
    api_key = OPENAI_API_KEY
    
    # Then try environment variable if constant is empty
    if not api_key:
        api_key = os.environ.get('OPENAI_API_KEY')
    
    # Then check for config file in user's home directory
    if not api_key:
        config_path = os.path.expanduser('~/.openai_config')
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r') as f:
                    config = json.load(f)
                    api_key = config.get('api_key')
            except Exception:
                pass
    
    # If still no API key, prompt user
    if not api_key:
        print("OpenAI API key not found. Please enter your API key:")
        api_key = input("> ").strip()
        
        if api_key:
            # Save for future use (optional)
            try:
                if input("Save API key for future use? (y/n): ").lower() == 'y':
                    os.makedirs(os.path.dirname(config_path), exist_ok=True)
                    with open(config_path, 'w') as f:
                        json.dump({'api_key': api_key}, f)
                    os.chmod(config_path, 0o600)  # Restrict permissions
            except Exception as e:
                print(f"Error saving API key: {e}")
    
    return api_key

def summarize_speaker(speaker_name, speaker_entries, api_key):
    """
    Summarize contributions from a specific speaker
    
    Args:
        speaker_name (str): Speaker name
        speaker_entries (list): List of transcript entries for this speaker
        api_key (str): OpenAI API key
        
    Returns:
        str: Summary of speaker contributions
    """
    if not api_key:
        return "API key not provided. Summaries not generated."
    
    # Collect all text from this speaker
    speaker_text = ""
    for entry in speaker_entries:
        speaker_text += f"[{entry['time_str']}] {entry['text']}\n\n"
    
    if not speaker_text.strip():
        return "No text available for summarization."
    
    try:
        openai.api_key = api_key
        
        # Construct prompt
        prompt = (
            "Summarize this speaker's contributions in one paragraph. "
            "Start with the key topic, then provide a summary (no line breaks). "
            "Example format: 'Optimization of UMAP and JSON Communication: Adam Smith presented specific...' "
            "Be technical, clear, and precise. Don't hallucinate. "
            "Use bolding for important words and concepts, but not for the speaker name.\n\n"
            f"TRANSCRIPT ENTRIES FOR {speaker_name}:\n\n{speaker_text}"
        )
        
        # Using chat completions API
        response = openai.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": "You are a technical meeting summarizer."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=400,
        )
        
        return response.choices[0].message.content.strip()
    
    except Exception as e:
        return f"Error generating summary: {str(e)}"

def summarize_batch(batch_entries, batch_number, api_key):
    """
    Summarize a batch of transcript entries using OpenAI API
    
    Args:
        batch_entries (list): List of transcript entries for this batch
        batch_number (int): Batch number for identification
        api_key (str): OpenAI API key
        
    Returns:
        str: Batch summary with topics and timestamps
    """
    if not api_key:
        return "API key not provided. Summaries not generated."
    
    # Extract batch text
    batch_text = extract_text_for_batch(batch_entries)
    
    if not batch_text.strip():
        return "No text available for summarization."
    
    # Get start and end times
    start_seconds = min(entry['seconds'] for entry in batch_entries)
    # End time is either explicit end_seconds or last entry
    if any('end_seconds' in entry for entry in batch_entries):
        # Use the max end_seconds if available
        end_seconds = max(entry.get('end_seconds', entry['seconds']) for entry in batch_entries)
    else:
        # Otherwise use the last entry in the batch
        end_seconds = max(entry['seconds'] for entry in batch_entries)
    
    start_time = seconds_to_time_str(start_seconds)
    end_time = seconds_to_time_str(end_seconds)
    
    # Create a mapping of speaker names to ALL their timestamps for this batch
    speaker_timestamps = {}
    for entry in batch_entries:
        speaker = entry['name']
        if speaker not in speaker_timestamps:
            speaker_timestamps[speaker] = []
        
        # Add this timestamp to the list for this speaker
        speaker_timestamps[speaker].append({
            'seconds': entry['seconds'],
            'time_str': entry['time_str'],
            'text': entry['text'][:100]  # Include a snippet of text for context
        })
    
    # Prepare the timestamp reference for the model
    timestamp_reference = "SPEAKER TIMESTAMPS (DO NOT MODIFY THESE):\n"
    for speaker, timestamps in speaker_timestamps.items():
        # Sort timestamps chronologically
        sorted_timestamps = sorted(timestamps, key=lambda x: x['seconds'])
        
        # Include all timestamps for the speaker with context snippets
        timestamp_reference += f"{speaker}:\n"
        for i, ts in enumerate(sorted_timestamps, 1):
            timestamp_reference += f"  {i}. {ts['time_str']} - '{ts['text']}...'\n"
    
    try:
        openai.api_key = api_key
        
        # Construct prompt for batch summary with explicit timestamp instruction
        prompt = (
            "Summarize in detail the most important ideas of our meeting. "
            "Be detailed, thorough, technical, clear, and precise. Don't hallucinate. "
            "Format must be full paragraphs with bolded important words, and bold in-line headers (but no line breaks). "
            "Use exactly this format: **Topic Title - Speaker Name** (H:MM:SS): Content... "
            "Where H:MM:SS is the timestamp in hours:minutes:seconds format. "
            "VERY IMPORTANT: You MUST use the EXACT timestamps provided in the SPEAKER TIMESTAMPS section below. "
            "DO NOT make up or modify any timestamps - use ONLY the exact timestamps provided for each speaker. "
            "IMPORTANT: For each topic, select the MOST RELEVANT timestamp instance for the speaker based on the context snippet. "
            "Don't just use the first timestamp for a speaker - carefully match the topic to the most appropriate instance "
            "where that speaker discusses that specific topic. "
            "The timestamps are crucial as they will be used to generate direct video links. "
            "Explain each key idea in depth without leaving out any details. "
            "For each idea, also describe other participants involved in the discussion. "
            "After summarizing the topics, DO NOT end with an overall summarizing sentence or paragraph. "
            f"\n\n{timestamp_reference}\n\n"
            f"MEETING TRANSCRIPT BATCH #{batch_number} ({start_time} - {end_time}):\n\n{batch_text}"
        )
        
        # Using chat completions API
        response = openai.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": "You are a technical meeting summarizer. NEVER modify the timestamps provided to you."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=10000,  # More tokens for batch summaries
        )
        
        summary = response.choices[0].message.content.strip()
        
        # Post-process to verify timestamps are from the provided list
        for speaker, timestamps in speaker_timestamps.items():
            # Create a set of valid timestamps for this speaker
            valid_timestamps = {ts['time_str'] for ts in timestamps}
            
            # Look for patterns like "**Topic - Speaker** (H:MM:SS):" with timestamps
            pattern = f"\\*\\*[^*]+ - {re.escape(speaker)}\\*\\* \\(([0-9]:[0-9]{{2}}:[0-9]{{2}})\\)"
            matches = re.finditer(pattern, summary)
            
            for match in matches:
                found_timestamp = match.group(1)
                
                # Check if the timestamp is valid for this speaker
                if found_timestamp not in valid_timestamps:
                    # Use the first timestamp as fallback
                    fallback_timestamp = timestamps[0]['time_str']
                    
                    # Replace the incorrect timestamp with a valid one
                    summary = summary.replace(
                        f"**{match.group(0).split('**')[1]}** ({found_timestamp})",
                        f"**{match.group(0).split('**')[1]}** ({fallback_timestamp})"
                    )
                    print(f"Warning: Replaced invalid timestamp {found_timestamp} with {fallback_timestamp} for {speaker}")
        
        return summary
    
    except Exception as e:
        return f"Error generating batch summary: {str(e)}"

# -------------------------------------------------------------
# Main Processing Function
# -------------------------------------------------------------
def process_xlsx(xlsx_file, video_id, html_file=None, format_type='simple', summary_file=None,
                speaker_summary_file=None, meeting_summary_md_file=None, batch_size_minutes=DEFAULT_BATCH_SIZE_MINUTES):
    """
    Process Excel file to generate HTML links with summaries and meeting summaries
    
    Args:
        xlsx_file (str): Path to input Excel file
        video_id (str): Panopto video ID
        html_file (str, optional): Path to output HTML file for speaker links
        format_type (str, optional): Format type ('simple' or 'numbered')
        summary_file (str, optional): Path to output HTML file for meeting summaries
        speaker_summary_file (str, optional): Path to output Markdown file for speaker summaries
        meeting_summary_md_file (str, optional): Path to output Markdown file for meeting summaries
        batch_size_minutes (int, optional): Batch size in minutes (default: DEFAULT_BATCH_SIZE_MINUTES)
        
    Returns:
        tuple: Paths to the generated files (html_file, summary_file, speaker_summary_file, meeting_summary_md_file)
    """
    if html_file is None:
        html_file = os.path.splitext(xlsx_file)[0] + '_speaker_summaries.html'
    
    if speaker_summary_file is None:
        speaker_summary_file = os.path.splitext(xlsx_file)[0] + '_speaker_summaries.md'
    
    if summary_file is None:
        summary_file = os.path.splitext(xlsx_file)[0] + '_meeting_summaries.html'
    
    if meeting_summary_md_file is None:
        meeting_summary_md_file = os.path.splitext(xlsx_file)[0] + '_meeting_summaries.md'
    
    # Ensure video_id is provided
    if not video_id:
        raise ValueError("Panopto video ID is required")
    
    # Get OpenAI API key
    api_key = get_api_key()
    if not api_key:
        print("Warning: OpenAI API key not provided. Summaries will not be generated.")
        return None, None, None, None
    
    try:
        # Read the Excel file
        df = pd.read_excel(xlsx_file)
        
        # Extract speaker links
        speaker_links = extract_unique_speakers(df)
        
        # Extract full transcript data
        transcript_data = extract_transcript_data(df)
        
        # Process speaker summaries
        print(f"Generating summaries for {len(speaker_links)} speakers...")
        for i, speaker in enumerate(speaker_links):
            name = speaker['name']
            print(f"Processing speaker {i+1}/{len(speaker_links)}: {name}")
            
            # Get all entries for this speaker
            speaker_entries = [entry for entry in transcript_data if entry['name'] == name]
            
            # Generate summary
            if speaker_entries:
                summary = summarize_speaker(name, speaker_entries, api_key)
                
                # Add summary to all entries for this speaker
                for entry in speaker_entries:
                    entry['summary'] = summary
        
        # Generate HTML output
        if format_type.lower() == 'numbered':
            html_lines = generate_numbered_format(speaker_links, transcript_data, video_id)
        else:  # simple format
            html_lines = generate_simple_format(speaker_links, transcript_data, video_id)
        
        # Write the HTML file
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(html_lines))
        
        # Generate speaker summary markdown
        speaker_summary_lines = generate_speaker_summary(speaker_links, transcript_data, video_id)
        
        # Write the speaker summary md file
        with open(speaker_summary_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(speaker_summary_lines))
        
        print(f"Generated speaker summary markdown: {speaker_summary_file}")
        print(f"Generated HTML with links and summaries: {html_file}")
        
        # Create time-based batches directly from transcript data
        print("Creating time-based batches for meeting summaries...")
        batches = create_time_batches(transcript_data, batch_size_minutes)
        print(f"Created {len(batches)} batches")
        
        # Generate batch summaries
        batch_summaries = []
        for i, batch in enumerate(batches, 1):
            # Get start and end times for this batch
            start_seconds = min(entry['seconds'] for entry in batch)
            # End time is either explicit end_seconds or last entry
            if any('end_seconds' in entry for entry in batch):
                end_seconds = max(entry.get('end_seconds', entry['seconds']) for entry in batch)
            else:
                end_seconds = max(entry['seconds'] for entry in batch)
            
            start_time = seconds_to_time_str(start_seconds)
            end_time = seconds_to_time_str(end_seconds)
            
            print(f"Processing batch {i}/{len(batches)}: {start_time} - {end_time}")
            
            # Generate summary
            summary = summarize_batch(batch, i, api_key)
            batch_summaries.append(summary)
        
        # Generate meeting summaries HTML with topic-level clickable links
        # Pass transcript_data for improved timestamp matching
        generate_meeting_summaries_html(batches, batch_summaries, video_id, summary_file, transcript_data)
        print(f"Generated meeting summaries HTML: {summary_file}")
        
        # Generate meeting summaries Markdown with topic-level clickable links
        # Pass transcript_data for improved timestamp matching
        generate_meeting_summaries_markdown(batches, batch_summaries, video_id, meeting_summary_md_file, transcript_data)
        print(f"Generated meeting summaries Markdown: {meeting_summary_md_file}")
        
        return html_file, summary_file, speaker_summary_file, meeting_summary_md_file
    
    except Exception as e:
        print(f"Error processing Excel file: {e}", file=sys.stderr)
        raise

def main():
    """
    Main function to handle command-line arguments and process Excel file
    """
    # Set up argument parser
    parser = argparse.ArgumentParser(description='Convert Excel transcript to HTML links with summaries')
    parser.add_argument('input_file', help='Input Excel file')
    parser.add_argument('video_id', help='Panopto video ID (required)')
    parser.add_argument('output_file', nargs='?', help='Output HTML file (optional)')
    parser.add_argument('--format', choices=['simple', 'numbered'], default='numbered',
                     help='Output format: simple or numbered (default: numbered)')
    parser.add_argument('--summary-file', help='Output file for meeting summaries HTML (optional)')
    parser.add_argument('--speaker-summary-file', help='Output file for speaker summaries markdown (optional)')
    parser.add_argument('--meeting-summary-md-file', help='Output file for meeting summaries markdown (optional)')
    parser.add_argument('--batch-size', type=int, default=DEFAULT_BATCH_SIZE_MINUTES,
                     help=f'Batch size in minutes (default: {DEFAULT_BATCH_SIZE_MINUTES})')
    
    args = parser.parse_args()
    
    try:
        html_file, summary_html_file, speaker_summary_file, meeting_summary_md_file = process_xlsx(
            args.input_file,
            args.video_id,
            args.output_file,
            args.format,
            args.summary_file,
            args.speaker_summary_file,
            args.meeting_summary_md_file,
            args.batch_size
        )
        
        if html_file and summary_html_file:
            print(f"Processing complete!")
            print(f"Speaker links HTML: {html_file}")
            print(f"Speaker summary Markdown: {speaker_summary_file}")
            print(f"Meeting summaries HTML: {summary_html_file}")
            print(f"Meeting summaries Markdown: {meeting_summary_md_file}")
        
    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    main()